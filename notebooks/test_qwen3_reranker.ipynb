{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f44460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b148c2d",
   "metadata": {},
   "source": [
    "### 1.0 Handling permutations of input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3089e97",
   "metadata": {},
   "source": [
    "Read this: https://realpython.com/python-zip-function/#passing-arguments-of-unequal-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b3bf2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'I', '!'), (1, 'love', '!'), (1, 'Satay', '!')]\n"
     ]
    }
   ],
   "source": [
    "a = [1]\n",
    "b = ['I', 'love', 'Satay']\n",
    "c = ['!']\n",
    "\n",
    "output_list = list(product(a, b, c))\n",
    "print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87dffcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'I', '!'),\n",
       " (1, 'love', '!'),\n",
       " (1, 'Satay', '!'),\n",
       " (2, 'I', '!'),\n",
       " (2, 'love', '!'),\n",
       " (2, 'Satay', '!')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(a, b, c) for a, b, c in output_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26a03c",
   "metadata": {},
   "source": [
    "### 2.0 Reranker Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33f42f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen3TextReranker:\n",
    "    \"\"\"A class for reranking text using the Qwen3 model.\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str = 'Qwen/Qwen3-Reranker-0.6B',\n",
    "            max_length: int = 8192,\n",
    "            prefix: str = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\",\n",
    "            suffix: str = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "        ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            padding_side='left'\n",
    "        )\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            attn_implementation=\"flash_attention_2\",\n",
    "            torch_dtype=torch.float16,\n",
    "        ).to(self.device)\n",
    "        self.token_false_id = self.tokenizer.convert_tokens_to_ids(\"no\")\n",
    "        self.token_true_id = self.tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "        self.prefix_tokens = self.tokenizer.encode(prefix, add_special_tokens=False)\n",
    "        self.suffix_tokens = self.tokenizer.encode(suffix, add_special_tokens=False)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_instruction(\n",
    "        query: str,\n",
    "        doc: str,\n",
    "        instruction: str = 'Given a search query, retrieve relevant passages that answer the query',\n",
    "    ) -> str:\n",
    "        output = f\"<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}\"\n",
    "        return output\n",
    "\n",
    "    def _process_inputs(self, pairs) -> Tensor:\n",
    "        inputs = self.tokenizer(\n",
    "            pairs, padding=False, truncation='longest_first',\n",
    "            return_attention_mask=False, max_length=self.max_length - len(self.prefix_tokens) - len(self.suffix_tokens)\n",
    "        )\n",
    "        for i, ele in enumerate(inputs['input_ids']):\n",
    "            inputs['input_ids'][i] = self.prefix_tokens + ele + self.suffix_tokens\n",
    "        inputs = self.tokenizer.pad(inputs, padding=True, return_tensors=\"pt\", max_length=self.max_length)\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(self.device)\n",
    "        return inputs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def rerank(\n",
    "        self,\n",
    "        query: str, # limit to 1 query\n",
    "        documents: List[str],\n",
    "        instruction: Optional[str] = None,\n",
    "        **kwargs\n",
    "    ) -> npt.NDArray[np.float16]:\n",
    "        query_doc_permutation = []\n",
    "        pairs = []\n",
    "        query = [query]\n",
    "\n",
    "        if instruction:\n",
    "            instruction = [instruction]\n",
    "            print(instruction)\n",
    "            query_doc_permutation = list(product(query, documents, instruction))\n",
    "            pairs = [self._format_instruction(query, doc, instruc) for query, doc, instruc in query_doc_permutation]\n",
    "            print(pairs)\n",
    "        else:\n",
    "            query_doc_permutation = list(product(query, documents))\n",
    "            pairs = [self._format_instruction(query, doc) for query, doc in query_doc_permutation]\n",
    "\n",
    "        inputs = self._process_inputs(pairs)\n",
    "\n",
    "        batch_scores = self.model(**inputs).logits[:, -1, :]\n",
    "        true_vector = batch_scores[:, self.token_true_id]\n",
    "        false_vector = batch_scores[:, self.token_false_id]\n",
    "        batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "        batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "        scores = batch_scores[:, 1].exp().detach().cpu().numpy()\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2add7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the embedding model\n",
    "embedder = Qwen3TextReranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d47fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f94a5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Given a search query, determine relevant passages that answer the query']\n",
      "['<Instruct>: Given a search query, determine relevant passages that answer the query\\n<Query>: What is the capital of China?\\n<Document>: The capital of China is Beijing.', '<Instruct>: Given a search query, determine relevant passages that answer the query\\n<Query>: What is the capital of China?\\n<Document>: The capital of Malaysia is Kuala Lumpur', '<Instruct>: Given a search query, determine relevant passages that answer the query\\n<Query>: What is the capital of China?\\n<Document>: Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.']\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of China?\"\n",
    "\n",
    "documents = [\n",
    "    \"The capital of China is Beijing.\",\n",
    "    \"The capital of Malaysia is Kuala Lumpur\",\n",
    "    \"Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun.\",\n",
    "]\n",
    "\n",
    "instruction = 'Given a search query, determine relevant passages that answer the query'\n",
    "\n",
    "test = embedder.rerank(query, documents, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d7f7ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78afcc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05853ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the capital of China? | Document: The capital of China is Beijing. | Score: 0.99951171875\n",
      "Query: What is the capital of China? | Document: The capital of Malaysia is Kuala Lumpur | Score: 5.1021575927734375e-05\n",
      "Query: What is the capital of China? | Document: Gravity is a force that attracts two bodies towards each other. It gives weight to physical objects and is responsible for the movement of planets around the sun. | Score: 4.231929779052734e-06\n"
     ]
    }
   ],
   "source": [
    "for d, a in zip(documents, test):\n",
    "    print(f'Query: {query} | Document: {d} | Score: {a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b620d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float16(5.1e-05)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-embeddings-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
